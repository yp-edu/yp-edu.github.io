---
title: Contrastive Sparse Autoencoders for Interpreting Planning of Chess-Playing Agents
tldr: We propose contrastive sparse autoencoders (CSAE), a novel framework for studying pairs of game trajectories. Using CSAE, we are able to extract and interpret concepts that are meaningful to the chess-agent plans. We primarily focused on a qualitative analysis of the CSAE features before proposing an automated feature taxonomy. Furthermore, to evaluate the quality of our trained CSAE, we devise sanity checks to wave spurious correlations in our results.
tags:
  - Chess
  - XAI
references: 
aliases: 
crossposts: 
publishedOn: 2024-06-05
editedOn: 2024-06-05
authors:
  - "[[Yoann Poupart]]"
readingTime: 25
image: /assets/publications/images/lczero-planning_thumbnail.png
description: TL;DR> We propose contrastive sparse autoencoders (CSAE), a novel framework for studying pairs of game trajectories. Using CSAE, we are able to extract and interpret concepts that are meaningful to the chess-agent plans. We primarily focused on a qualitative analysis of the CSAE features before proposing an automated feature taxonomy. Furthermore, to evaluate the quality of our trained CSAE, we devise sanity checks to wave spurious correlations in our results.
---

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Contrastive Sparse Autoencoders for Interpreting Planning of Chess-Playing Agents</h1>
          <div class="is-size-5 publication-authors">
            <!-- Paper authors -->
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=hX7LNgUAAAAJ&hl=fr" target="_blank">Yoann Poupart</a><sup>*</sup>
            </span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">ENS de Lyon<br>Worskhop on Interpretable Policies in Reinforcement Learning @ RLC-2024 </span>
          </div>
          <div class="column has-text-centered">
            <div class="publication-links">
                  <!-- Arxiv PDF link -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2406.04028.pdf" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

              <!-- Github link -->
              <span class="link-block">
                <a href="https://github.com/Xmaster6y/lczero-planning" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i> 
                  </span>
                  <span>Code</span>
                </a>
              </span>

              <span class="link-block">
                <a href="https://huggingface.co/spaces/Xmaster6y/lczero-planning-demo" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-hand-pointer"></i>
                  </span>
                  <span>HF Space</span>
                </a>
              </span>

              <span class="link-block">
                <a href="https://openreview.net/forum?id=qVtp4lbuCN" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-pen"></i>
                  </span>
                  <span>OpenReview (RLC)</span>
                </a>
              </span>

              <!-- ArXiv abstract Link -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2406.04028" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="/assets/publications/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section> -->
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            AI led chess systems to a superhuman level, yet these systems heavily rely on black-box algorithms. This is unsustainable in ensuring transparency to the end-user, particularly when these systems are responsible for sensitive decision-making. Recent interpretability work has shown that the inner representations of Deep Neural Networks (DNNs) were fathomable and contained human-understandable concepts. Yet, these methods are seldom contextualised and are often based on a single hidden state, which makes them unable to interpret multi-step reasoning, e.g. planning. In this respect, we propose contrastive sparse autoencoders (CSAE), a novel framework for studying pairs of game trajectories. Using CSAE, we are able to extract and interpret concepts that are meaningful to the chess-agent plans. We primarily focused on a qualitative analysis of the CSAE features before proposing an automated feature taxonomy. Furthermore, to evaluate the quality of our trained CSAE, we devise sanity checks to wave spurious correlations in our results.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item is-centered has-text-centered">
          <img src="/assets/publications/images/lczero-planning_dynamical-concepts.pdf" alt="Dynamical Concetps"/>
          <h2 class="subtitle has-text-centered">
            Dynamical concepts illustration.
          </h2>
        </div>
        <div class="item is-centered has-text-centered">
          <img src="/assets/publications/images/lczero-planning_csae.pdf" alt="CSAE"/>
          <h2 class="subtitle has-text-centered">
            Contrastive Sparse Autoencoders (CSAE) schematic view.
          </h2>
        </div>
        <div class="item is-centered has-text-centered">
          <img src="/assets/publications/images/lczero-planning_extraction.pdf" alt="Dynamical concepts extraction"/>
          <h2 class="subtitle has-text-centered">
            Dynamical concepts extraction.
          </h2>
        </div>
        <div class="item is-centered has-text-centered">
          <img src="/assets/publications/images/lczero-planning_analysis.pdf" alt="CSAE features analysis"/>
          <h2 class="subtitle has-text-centered">
            CSAE features analysis.
          </h2>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End image carousel -->


<section class="section hero">
  <div class="hero-body">
    <div class="container is-centered has-text-centered">
      <iframe  
        src="https://lczero-planning-demo.hf.space"
        frameborder="0" 
        width="100%"
        height="800"
        style="border-radius: 10px;"
      ></iframe>
    </div>
  </div>
</section>


<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Reviews</h2>
        <div class="is-size-5 publication-authors">
          <span class="author-block">Mechanistic Interpretability Workshop @ ICML-2024 </span>
        </div>
        <div class="column has-text-centered">
          <div class="publication-links">
            <span class="link-block">
              <a href="https://openreview.net/forum?id=tXe9BqcjNY" target="_blank"
              class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fas fa-pen"></i>
                </span>
                <span>OpenReview (ICML)</span>
              </a>
            </span>
          </div>
        </div>
        <div>
          <span>Main criticisms:</span>
        </div>
        <div class="content has-text-justified">
          <ul>
            <li>
              <strong>Not enough training details:</strong> The training of the CSAE is under-detailed, particularly concerning the choice of hyperparameters, 
              data generation, and evaluation metrics. 
              Specific layers used for training and the integration of the contrast loss are not clearly explained, making it difficult to replicate or understand the methodology fully.
            </li>
            <li>
              <strong>Lack of comparison with other methods:</strong> The paper fails to compare the proposed CSAE 
              method with other feature extraction techniques, such as standard Sparse Autoencoders (SAE), Independent Component Analysis (ICA), and other clustering or probing methods. 
              This comparison is crucial to validate the efficacy and novelty of the CSAE over existing methods.
            </li>
            <li>
              <strong>Lack of feature interpretation:</strong> The interpretation of features generated by CSAE is inadequate. The paper does not convincingly demonstrate that the identified features correspond to meaningful chess concepts, 
              as only a few cherry-picked examples are provided without thorough validation of monosemanticity or broader representativeness.
            </li>
            <li>
              <strong>No utilisation of the proposed clustering:</strong>   Although clustering and dendrogram techniques are mentioned, they are not effectively used to enhance the understanding of the feature space. 
              The paper does not provide labeled clusters or investigate the similarity within clusters to help readers understand the model’s internal representation.
            </li>
            <li>
              <strong>Insufficient qualitative and quantitative evaluations:</strong>   The qualitative assessments do not scale well 
              with human effort, and there's a lack of extensive qualitative evidence to support the interpretability of learned features. Quantitatively, the performance metrics like F1, precision, and recall are barely above threshold levels, and no robust statistical analysis is provided to support the findings. Moreover, there's a gap in demonstrating 
              how these features impact chess-playing decisions in practical scenarios.
            </li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Roadmap</h2>
        <div class="container content has-text-justified">
          <h3 class="subtitle subtitle-custom is-5">I propose the following roadmap to address the reviews:</h3>
          <ul class="checkbox-list">
            <li>
              <input type="checkbox" onclick="return false;"/> <strong> Enhanced method evaluation:</strong> 
              Currently, the paper lacks comparative analysis with other methods. 
              To address this, I plan to conduct evaluations against simple heuristic models to determine how 
              effectively my method extracts meaningful features. Additionally, I will compare the performance of Contrastive Sparse Autoencoders (CSAEs) with standard Sparse Autoencoders (SAE) and other relevant techniques to establish a clear benchmark.
            </li>
            <li>
              <input type="checkbox" onclick="return false;"/> <strong>Feature ablation study:</strong> I will carry out an ablation study to assess the impact of individual features extracted by the CSAE on the decision-making process of the chess agent. 
              This will help quantify the contribution of each feature towards enhancing the agent’s planning capabilities.
            </li>
            <li>
              <input type="checkbox" onclick="return false;"/> <strong>Expose more features:</strong> In addition to the Huggingface space created for the paper, I will provide a more detailed
              analysis of the features extracted by the CSAE.
            </li>
            <li>
              <input type="checkbox" onclick="return false;"/> <strong>Remove or rethink the clustering approach:</strong> While theoretically the clustering approach would 
              be interesting to scale human analysis it is not clear how it would be used in practice. 
              I have no clear idea on how to address this issue yet and might remove it from the paper.
            </li>
          </ul>
          <h3 class="subtitle subtitle-custom is-5">What I might leave out for further work:</h3>
          <ul class="checkbox-list">
            <li>
              <input type="checkbox" onclick="return false;"/> <strong>Establishing a proper benchmark: </strong> Setting up a robust benchmark, particularly in the context of chess, 
                would address many criticisms and provide a more objective evaluation of the CSAE. However, due to the significant work required, 
                I consider this an essential next step for future research rather than for inclusion in the current paper revision
            </li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <source src="/assets/publications/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <source src="/assets/publications/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            <source src="/assets/publications/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->





<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe
        src="/assets/publications/pdfs/sample.pdf" 
        width="100%" 
        height="550"
        style="border-radius: 10px;"
      ></iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre>
<code>@inproceedings{poupart2024contrastive,
  title={Contrastive Sparse Autoencoders for Interpreting Planning of Chess-Playing Agents},
  author={Poupart, Yoann},
  year={2024},
  booktitle={Workshop on Interpretable Policies in Reinforcement Learning@ RLC-2024}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->
